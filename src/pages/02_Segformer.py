# src/pages/02_Segformer.py
import streamlit as st
st.set_page_config(page_title="2. Segformer", page_icon="游댌")
st.title("2. Arquitectura detallada de SegFormer")
st.markdown("""
## Introducci칩n

SegFormer propone un dise침o simple pero eficiente para segmentaci칩n sem치ntica basado en Transformers, que combina un encoder jer치rquico con un decoder ligero y sin uso de positional embeddings, permitiendo alta precisi칩n y velocidad.
""")
st.image("data/images/003_segformer_img.png", caption="Segmentacion Semantica", width=1000)
st.image("data/images/ARQUITECTURAIMAGEN.png",
            caption="Arquitectura SegFormer (Encoder + Decoder)")
st.markdown("""
## Encoder: Mix Transformer (MiT)

- El encoder es un Transformer jer치rquico con m칰ltiples etapas, inspirado en arquitecturas de visi칩n como Swin Transformer pero con simplificaciones.
- Cada etapa procesa la imagen a distintas resoluciones, extrayendo caracter칤sticas con diferentes escalas espaciales (1/4, 1/8, 1/16, 1/32 del tama침o original).
- El encoder emplea **mezcla local y global** mediante la auto-atenci칩n eficiente con ventanas y reducci칩n progresiva, logrando un buen balance entre precisi칩n y eficiencia.
- MiT-B0, la versi칩n m치s ligera usada en este modelo, tiene **3.7 millones de par치metros** en el encoder.

## Decoder: MLP ligero y eficiente

- En lugar de decoders complejos o basados en convoluciones, SegFormer utiliza un **decoder simple basado en multilayer perceptrons (MLP)**.
- El decoder toma las caracter칤sticas jer치rquicas extra칤das en diferentes escalas, las proyecta a un espacio com칰n y las combina para producir las predicciones finales de segmentaci칩n.
- Esta simplicidad reduce par치metros y costos computacionales, permitiendo inferencia r치pida.
- El decoder tiene alrededor de **0.4 millones de par치metros**.

## Ventajas clave

- **Sin positional embeddings:** SegFormer elimina la necesidad de embeddings posicionales expl칤citos, usando mecanismos de atenci칩n y pooling que mantienen la informaci칩n espacial y permiten inferencia flexible en im치genes de diferentes tama침os.
- **Jerarqu칤a eficiente:** La arquitectura jer치rquica captura tanto detalles finos como contexto global.
- **Alta velocidad y precisi칩n:** En resoluci칩n 512x512, SegFormer puede alcanzar hasta **47 FPS** en GPU, con resultados de precisi칩n competitivos en datasets est치ndares como ADE20k y Cityscapes.
- **Dise침o modular:** Facilita adaptaci칩n a diferentes tama침os de modelo (MiT-B0 a MiT-B5) y a distintas tareas de segmentaci칩n.

## Par치metros y desempe침o (MiT-B0)

| Componente  | Par치metros (millones) |
|-------------|-----------------------|
| Encoder     | 3.7                   |
| Decoder     | 0.4                   |
| **Total**   | **~4.1**              |

## Referencias

- Xie et al., "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers", *NeurIPS 2021*.
- [Paper completo](https://arxiv.org/abs/2105.15203)
""")