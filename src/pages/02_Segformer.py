import streamlit as st
import os

st.set_page_config(
    page_title="SegFormer",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        "About": "Esta app fue creada por Marce para demo de Segmentaci√≥n Sem√°ntica."
    }
)


st.title("SegFormer")

st.markdown("""
Es un modelo de NVIDIA con una arquitectura reciente basada en Transformers dise√±ada espec√≠ficamente para segmentaci√≥n sem√°ntica con eficiencia y precisi√≥n.  
SegFormer combina un encoder jer√°rquico eficiente que captura caracter√≠sticas a m√∫ltiples escalas y un decoder ligero que integra estas caracter√≠sticas para producir una segmentaci√≥n precisa.
Todo esto sin necesidad de embeddings posicionales.

Algunas caracter√≠sticas destacadas de SegFormer:

- Al no trabajar con embeddings posicionales, puede manejar im√°genes de tama√±os variados sin p√©rdida de informaci√≥n espacial.  
- Arquitectura simple pero potente, con un balance √≥ptimo entre n√∫mero de par√°metros y velocidad.  
- Entrenado sobre datasets est√°ndares como ADE20k, logrando resultados de punta en benchmarks p√∫blicos al momento de su publicaci√≥n.

Para m√°s detalles t√©cnicos y resultados, puedes consultar el [paper original de SegFormer](https://arxiv.org/abs/2105.15203).

## Algunos ejemplos de segmentaci√≥n sem√°ntica con SegFormer
""")

segformer_examples = [
    "data/images/001_segformer_img.png",
    "data/images/002_segformer_img.png",
    "data/images/003_segformer_img.png"
]

captions = [
    "Segmentaci√≥n Sem√°ntica - Moto en el aire",
    "Segmentaci√≥n Sem√°ntica - Jugadores en el campo de b√©isbol",
    "Segmentaci√≥n Sem√°ntica - Surfistas en la playa"
    ]

# Inicializar el √≠ndice en session_state
if "carousel_index" not in st.session_state:
    st.session_state.carousel_index = 0

# Crear layout con 3 columnas
col1, col2, col3 = st.columns([1, 6, 1])

with col1:
    if st.button("‚óÄ", use_container_width=True) and st.session_state.carousel_index > 0:
        st.session_state.carousel_index -= 1

with col3:
    if st.button("‚ñ∂", use_container_width=True) and st.session_state.carousel_index < len(segformer_examples) - 1:
        st.session_state.carousel_index += 1

# Mostrar la imagen en el centro
with col2:
    current_idx = st.session_state.carousel_index
    if os.path.exists(segformer_examples[current_idx]):
        st.image(segformer_examples[current_idx], caption=captions[current_idx], use_container_width=True)
    else:
        st.warning(f"No se encontr√≥ la imagen: {segformer_examples[current_idx]}")

st.markdown("""
## Arquitectura del SegFormer """)

st.image("data/images/000_Architecture.png", caption="Arquitectura SegFormer (Encoder + Decoder)", width=800)

st.markdown("""
## Encoder: Mix Transformer (MiT)

- El encoder es un Transformer jer√°rquico con m√∫ltiples etapas, inspirado en arquitecturas de visi√≥n como Swin Transformer pero con simplificaciones.
- Cada etapa procesa la imagen a distintas resoluciones, extrayendo caracter√≠sticas con diferentes escalas espaciales (1/4, 1/8, 1/16, 1/32 del tama√±o original).
- El encoder emplea **mezcla local y global** mediante la auto-atenci√≥n eficiente con ventanas y reducci√≥n progresiva, logrando un buen balance entre precisi√≥n y eficiencia.
- MiT-B0, la versi√≥n m√°s ligera usada en este modelo, tiene **3.7 millones de par√°metros** en el encoder.

## Decoder: MLP ligero y eficiente

- En lugar de decoders complejos o basados en convoluciones, SegFormer utiliza un **decoder simple basado en multilayer perceptrons (MLP)**.
- El decoder toma las caracter√≠sticas jer√°rquicas extra√≠das en diferentes escalas, las proyecta a un espacio com√∫n y las combina para producir las predicciones finales de segmentaci√≥n.
- Esta simplicidad reduce par√°metros y costos computacionales, permitiendo inferencia r√°pida.
- El decoder tiene alrededor de **0.4 millones de par√°metros**.

## Ventajas clave

- **Sin positional embeddings:** SegFormer elimina la necesidad de embeddings posicionales expl√≠citos, usando mecanismos de atenci√≥n y pooling que mantienen la informaci√≥n espacial y permiten inferencia flexible en im√°genes de diferentes tama√±os.
- **Jerarqu√≠a eficiente:** La arquitectura jer√°rquica captura tanto detalles finos como contexto global.
- **Alta velocidad y precisi√≥n:** En resoluci√≥n 512x512, SegFormer puede alcanzar hasta **47 FPS** en GPU, con resultados de precisi√≥n competitivos en datasets est√°ndares como ADE20k y Cityscapes.
- **Dise√±o modular:** Facilita adaptaci√≥n a diferentes tama√±os de modelo (MiT-B0 a MiT-B5) y a distintas tareas de segmentaci√≥n.

## Par√°metros y desempe√±o (MiT-B0)

<table>
    <tr><th>Componente</th><th>Par√°metros (millones)</th></tr>
    <tr><td>Encoder</td><td>3.7</td></tr>
    <tr><td>Decoder</td><td>0.4</td></tr>
    <tr><th>Total</th><th>~4.1</th></tr>
</table>

## Referencias

- Xie et al., "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers", *NeurIPS 2021*.
- [Paper completo](https://arxiv.org/abs/2105.15203)
""", unsafe_allow_html=True)
