# SegFormer: Arquitectura Transformer para Segmentaci칩n Sem치ntica

SegFormer es un modelo desarrollado por **NVIDIA** que combina la potencia de las arquitecturas Transformer con eficiencia y precisi칩n para la tarea de segmentaci칩n sem치ntica en im치genes.

## 쯈u칠 es SegFormer?

- Es un modelo basado en Transformers dise침ado para segmentaci칩n sem치ntica.
- Combina un encoder jer치rquico sin embeddings posicionales con un decoder ligero.
- Permite segmentar im치genes con alta precisi칩n y eficiencia computacional.

## Arquitectura

### Encoder: Mix Transformer (MiT)

- Inspirado en el Swin Transformer, cuenta con un dise침o jer치rquico que procesa las im치genes en m칰ltiples resoluciones.
- Las escalas de procesamiento son: 1/4, 1/8, 1/16 y 1/32 de la resoluci칩n original.
- Mezcla mecanismos de atenci칩n local y global para capturar tanto detalles finos como contexto amplio.
- La versi칩n m치s ligera, MiT-B0, cuenta con aproximadamente 3.7 millones de par치metros.

### Decoder: MLP Eficiente

- Un decoder simple basado en capas MLP que proyecta y fusiona caracter칤sticas de distintas escalas.
- Su dise침o ligero mantiene la eficiencia sin sacrificar precisi칩n.
- Cuenta con alrededor de 0.4 millones de par치metros.

## Ventajas Clave

- **Sin Embeddings Posicionales:** Esto permite que el modelo trabaje con im치genes de tama침os variados sin perder precisi칩n espacial.
- **Jerarqu칤a eficiente:** El encoder jer치rquico proporciona un equilibrio 칩ptimo entre contexto global y detalles locales.
- **Alta Velocidad de Inferencia:** Capaz de procesar im치genes hasta a 47 FPS, ideal para aplicaciones en tiempo real.
- **Modularidad:** Dispone de diferentes versiones (MiT-B0 a MiT-B5) para adaptar el modelo a distintos requerimientos de recursos y precisi칩n.

## Par치metros Totales (MiT-B0)

| Componente | Par치metros (Millones) |
|------------|----------------------|
| Encoder    | 3.7                  |
| Decoder    | 0.4                  |
| **Total**  | **~4.1**             |

## Referencias

- Xie et al., "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers", NeurIPS 2021  
  [游늯 Paper en arXiv](https://arxiv.org/abs/2105.15203)
